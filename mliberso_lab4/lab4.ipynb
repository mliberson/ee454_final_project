{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6755855-7256-469d-89d7-7b28eb1fa399",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'google-cluster-data-1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-14b56a3c9d50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-14b56a3c9d50>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mtaskData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'google-cluster-data-1.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[1;31m#gathering csv data into a python dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mtaskInfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'TaskID'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtaskData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TaskID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'NrmlTaskCores'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtaskData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NrmlTaskCores'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'NrmlTaskMem'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtaskData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NrmlTaskMem'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtaskData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ExecutionTime'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtaskData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TaskID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'google-cluster-data-1.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def createTaskQueues2(taskInfo):\n",
    "    \n",
    "    taskQueues = {}\n",
    "    for time in range(90000,113100,300):\n",
    "        taskQueues[time] = []\n",
    "    time = 90000\n",
    "    for taskIdx in range(len(taskInfo['Time'])):\n",
    "        if(taskInfo['Time'][taskIdx] == time):\n",
    "            taskQueues[time].append(taskIdx)\n",
    "            if(taskInfo['ExecutionTime'][taskIdx] > 300):\n",
    "                taskQueues[time+300].append(taskIdx)\n",
    "        else:\n",
    "            time = time + 300\n",
    "    return taskQueues\n",
    "\n",
    "def powerConsumption(myVmSpace):\n",
    "    c = 5\n",
    "    a = 100\n",
    "    b = 200\n",
    "    threshold = 0.5\n",
    "    \n",
    "    Pwr_dy = 0\n",
    "    Pwr_st = 0\n",
    "    Pwr = 0\n",
    "    \n",
    "    for core in myVmSpace[0]:\n",
    "        coreUsage = 1-core/7\n",
    "        if(coreUsage > 0):\n",
    "            Pwr_st = c\n",
    "        if(coreUsage < threshold):\n",
    "            Pwr_dy = a*coreUsage\n",
    "        else:\n",
    "            Pwr_dy = a*threshold + b*(coreUsage-threshold)*(coreUsage-threshold)\n",
    "        Pwr = Pwr + Pwr_dy + Pwr_st\n",
    "    return Pwr\n",
    "\n",
    "def roundRobin(taskQueue,taskInfo,myVmSpace):\n",
    "               \n",
    "    VM_iter = 0\n",
    "    #will iterate through all possible starting VMs, incriments by one each time\n",
    "    VM_jter = 0\n",
    "    #incrimenter used when task does not fit in the first potentially available VM\n",
    "    \n",
    "    rejectQueue = []\n",
    "               \n",
    "    for i in taskQueue:\n",
    "        if(taskInfo['NrmlTaskCores'][i] <= myVmSpace[0][VM_iter] and taskInfo['NrmlTaskMem'][i] <= myVmSpace[1][VM_iter]):\n",
    "            #if the number of cores and memory space the task requires is less than the available for the VMS\n",
    "            #then we can allocate the task to the current VM\n",
    "            myVmSpace[0][VM_iter]  = myVmSpace[0][VM_iter] - taskInfo['NrmlTaskCores'][i]\n",
    "            myVmSpace[1][VM_iter]  = myVmSpace[1][VM_iter] - taskInfo['NrmlTaskMem'][i]\n",
    "            #now that the task is allocated, we have to update the amount of free CPU and memory space\n",
    "        else:\n",
    "            allocated = False\n",
    "            VM_jter = VM_iter+1\n",
    "            #move to the next VM\n",
    "            if(VM_jter == 100):\n",
    "                #make sure to loop back\n",
    "                VM_jter = 0\n",
    "            while(not allocated and VM_jter!=VM_iter):\n",
    "                #if it is allocated then don't keep looking\n",
    "                #if you've looked at all possible VMs and its not allocated, then it never will be so end loop\n",
    "                if(taskInfo['NrmlTaskCores'][i] <= myVmSpace[0][VM_jter] and taskInfo['NrmlTaskMem'][i] <= myVmSpace[1][VM_jter]):\n",
    "                    #if the number of cores and memory space the task requires is less than the available for the VMS\n",
    "                    #then we can allocate the task to the current VM\n",
    "                    myVmSpace[0][VM_jter] = myVmSpace[0][VM_jter] - taskInfo['NrmlTaskCores'][i]\n",
    "                    myVmSpace[1][VM_jter] = myVmSpace[1][VM_jter] - taskInfo['NrmlTaskMem'][i]\n",
    "                    #now that the task is allocated, we have to update the amount of free CPU and memory space\n",
    "                    allocated = True\n",
    "                    #allocate the task \n",
    "                VM_jter = VM_jter+1\n",
    "                #move to the next VM if its not allocated to the last one\n",
    "                if(VM_jter == 100):\n",
    "                    VM_jter = 0\n",
    "            if(not allocated):\n",
    "                rejectQueue.append(taskInfo['TaskID'][i])\n",
    "                #if the while loop finishes and the task is still not allocated\n",
    "                #then it cycled through all VMs and did not fit any, so it cannot be allocated and should be added to reject queue\n",
    "        VM_iter = VM_iter+1\n",
    "        if(VM_iter == 100):\n",
    "            VM_iter = 0\n",
    "\n",
    "    return rejectQueue, vms\n",
    "    \n",
    "def main():\n",
    "    taskData = pd.read_csv('google-cluster-data-1.csv',sep=' ') \n",
    "    #gathering csv data into a python dictionary\n",
    "    taskInfo = {'TaskID':taskData['TaskID'],'NrmlTaskCores':taskData['NrmlTaskCores'],'NrmlTaskMem':taskData['NrmlTaskMem'],'Time':taskData['Time'],'ExecutionTime':300*(taskData['TaskID']%2+1)}\n",
    "    #created a new python dictionary with more intuitive formatting\n",
    "    \n",
    "    np.save('taskID.npy',taskInfo['TaskID'])\n",
    "    np.save('taskCPU.npy',taskInfo['NrmlTaskCores'])\n",
    "    np.save('taskMEM.npy',taskInfo['NrmlTaskMem'])\n",
    "    np.save('exe_time_1.npy',taskInfo['ExecutionTime'])\n",
    "    \n",
    "    timeQ = 300\n",
    "\n",
    "    rejectQueue = [] \n",
    "    #queue of tasks that could not fit into any VM for all times\n",
    "    rejectQueue_t = []\n",
    "    \n",
    "    taskQueues = createTaskQueues2(taskInfo)\n",
    "    \n",
    "    Pwr_dy_t = {}\n",
    "    Pwr_st_t = {}\n",
    "    Pwr_t = {}\n",
    "    Cost_t = {}\n",
    "    \n",
    "    for time in range(90000,113100,300):\n",
    "        Pwr_dy_t[time] = []\n",
    "        Pwr_st_t[time] = []\n",
    "        Pwr_t[time] = []\n",
    "        Cost_t[time] = []\n",
    "    \n",
    "    Price_t = [0.5, 0.5, 0.6, 0.6, 0.6, 0.7, 0.7, 0.6, 0.6, 0.8, 0.8, 0.8, 0.8]\n",
    "    totalCost = 0\n",
    "    totalPwr = 0\n",
    "    \n",
    "    for time in range(90000,113100,timeQ):\n",
    "        taskQueue_t = taskQueues[time]\n",
    "        vms = [100*[7],100*[11]]\n",
    "        #reinitialize VMs for new time\n",
    "        rejectQueue_t, vms_t = roundRobin(taskQueue_t,taskInfo,myVmSpace)\n",
    "        if(rejectQueue_t != []):\n",
    "            rejectQueue.append(rejectQueue_t)\n",
    "        Pwr_t[time] = powerConsumption(vms_t)\n",
    "        totalPwr = totalPwr + (Pwr_t[time] * 300)\n",
    "        prcIdx = int((time - 90000)/3600)\n",
    "        Cost_t[time] = Price_t[prcIdx]*Pwr_t[time]\n",
    "        totalCost = totalCost + Cost_t[time]\n",
    "            \n",
    "    np.save('VMs_1.npy',myVmSpace)\n",
    "                \n",
    "    print(\"Number of rejected tasks is: {}\".format(len(rejectQueue)))\n",
    "    #print out the number of tasks that were rejected by the VMs\n",
    "    print(\"Total power use of tasks is: {}\".format(totalPwr)) # multiply by 300\n",
    "    print(\"Total cost of tasks is: {}\".format(totalCost))\n",
    "    \n",
    "    if(rejectQueue != []):\n",
    "        np.save('taskReject_1.npy',rejectQueue)\n",
    "        \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df20d9b-1092-444c-9f55-a4bb030fa465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rejected tasks is: 0\n",
      "Total power use of tasks is: 617857.1432187563\n",
      "Total cost of tasks is: 369147.2679653163\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def createTaskQueues10(taskInfo):\n",
    "    \n",
    "    taskQueues = {}\n",
    "    for time in range(90000,115500,300):\n",
    "        taskQueues[time] = []\n",
    "    time = 90000\n",
    "    for taskIdx in range(len(taskInfo['Time'])):\n",
    "        if(taskInfo['Time'][taskIdx] == time):\n",
    "            exTime = taskInfo['ExecutionTime'][taskIdx]\n",
    "            timeCnt = 0\n",
    "            while(exTime > 0):\n",
    "                taskQueues[time+timeCnt].append(taskIdx)\n",
    "                timeCnt = timeCnt + 300\n",
    "                exTime = exTime - 300\n",
    "        else:\n",
    "            time = time + 300\n",
    "    return taskQueues\n",
    "            \n",
    "def powerConsumption(myVmSpace,task_idx,vm_idx):\n",
    "    c = 5\n",
    "    a = 100\n",
    "    b = 200\n",
    "    threshold = 0.5\n",
    "    \n",
    "    Pwr_dy = 0\n",
    "    Pwr_st = 0\n",
    "    Pwr = 0\n",
    "    \n",
    "    NCU = myVmSpace[0][vm_idx] - df['NrmlTaskCores'][task_idx]\n",
    "    CCU \n",
    "    \n",
    "    coreUsage = NCU/25\n",
    "    if(coreUsage > 0):\n",
    "        Pwr_st = c\n",
    "    if(coreUsage < threshold):\n",
    "        Pwr_dy = a*coreUsage\n",
    "    else:\n",
    "        Pwr_dy = a*threshold + b*(coreUsage-threshold)*(coreUsage-threshold)\n",
    "    Pwr = Pwr_dy + Pwr_st\n",
    "    Pwr - \n",
    "    \n",
    "    \n",
    "    for core in myVmSpace[0]:\n",
    "        coreUsage = 1-core/25\n",
    "        if(coreUsage > 0):\n",
    "            Pwr_st = c\n",
    "        if(coreUsage < threshold):\n",
    "            Pwr_dy = a*coreUsage\n",
    "        else:\n",
    "            Pwr_dy = a*threshold + b*(coreUsage-threshold)*(coreUsage-threshold)\n",
    "        Pwr = Pwr + Pwr_dy + Pwr_st\n",
    "    return Pwr\n",
    "\n",
    "def roundRobin(taskQueue,taskInfo,myVmSpace):\n",
    "               \n",
    "    VM_iter = 0\n",
    "    #will iterate through all possible starting VMs, incriments by one each time\n",
    "    VM_jter = 0\n",
    "    #incrimenter used when task does not fit in the first potentially available VM\n",
    "    \n",
    "    rejectQueue = []\n",
    "               \n",
    "    for i in taskQueue:\n",
    "        if(taskInfo['NrmlTaskCores'][i] <= myVmSpace[0][VM_iter] and taskInfo['NrmlTaskMem'][i] <= myVmSpace[1][VM_iter]):\n",
    "            #if the number of cores and memory space the task requires is less than the available for the VMS\n",
    "            #then we can allocate the task to the current VM\n",
    "            myVmSpace[0][VM_iter]  = myVmSpace[0][VM_iter] - taskInfo['NrmlTaskCores'][i]\n",
    "            myVmSpace[1][VM_iter]  = myVmSpace[1][VM_iter] - taskInfo['NrmlTaskMem'][i]\n",
    "            #now that the task is allocated, we have to update the amount of free CPU and memory space\n",
    "        else:\n",
    "            allocated = False\n",
    "            VM_jter = VM_iter+1\n",
    "            #move to the next VM\n",
    "            if(VM_jter == 100):\n",
    "                #make sure to loop back\n",
    "                VM_jter = 0\n",
    "            while(not allocated and VM_jter!=VM_iter):\n",
    "                #if it is allocated then don't keep looking\n",
    "                #if you've looked at all possible VMs and its not allocated, then it never will be so end loop\n",
    "                if(taskInfo['NrmlTaskCores'][i] <= myVmSpace[0][VM_jter] and taskInfo['NrmlTaskMem'][i] <= myVmSpace[1][VM_jter]):\n",
    "                    #if the number of cores and memory space the task requires is less than the available for the VMS\n",
    "                    #then we can allocate the task to the current VM\n",
    "                    myVmSpace[0][VM_jter] = myVmSpace[0][VM_jter] - taskInfo['NrmlTaskCores'][i]\n",
    "                    myVmSpace[1][VM_jter] = myVmSpace[1][VM_jter] - taskInfo['NrmlTaskMem'][i]\n",
    "                    #now that the task is allocated, we have to update the amount of free CPU and memory space\n",
    "                    allocated = True\n",
    "                    #allocate the task \n",
    "                VM_jter = VM_jter+1\n",
    "                #move to the next VM if its not allocated to the last one\n",
    "                if(VM_jter == 100):\n",
    "                    VM_jter = 0\n",
    "            if(not allocated):\n",
    "                rejectQueue.append(taskInfo['TaskID'][i])\n",
    "                #if the while loop finishes and the task is still not allocated\n",
    "                #then it cycled through all VMs and did not fit any, so it cannot be allocated and should be added to reject queue\n",
    "        VM_iter = VM_iter+1\n",
    "        if(VM_iter == 100):\n",
    "            VM_iter = 0\n",
    "\n",
    "    return rejectQueue\n",
    "    \n",
    "def main():\n",
    "    taskData = pd.read_csv('google-cluster-data-1.csv',sep=' ') \n",
    "    #gathering csv data into a python dictionary\n",
    "    taskInfo = {'TaskID':taskData['TaskID'],'NrmlTaskCores':taskData['NrmlTaskCores'],'NrmlTaskMem':taskData['NrmlTaskMem'],'Time':taskData['Time'],'ExecutionTime':300*(taskData['TaskID']%10+1)}\n",
    "    #created a new python dictionary with more intuitive formatting\n",
    "    \n",
    "    np.save('taskID.npy',taskInfo['TaskID'])\n",
    "    np.save('taskCPU.npy',taskInfo['NrmlTaskCores'])\n",
    "    np.save('taskMEM.npy',taskInfo['NrmlTaskMem'])\n",
    "    np.save('exe_time_2.npy',taskInfo['ExecutionTime'])\n",
    "    \n",
    "    timeQ = 300\n",
    "\n",
    "    rejectQueue = [] \n",
    "    rejectQueue_t = []\n",
    "    #queue of tasks that could not fit into any VM for all times\n",
    "    \n",
    "    taskQueues = createTaskQueues10(taskInfo)\n",
    "    \n",
    "    Pwr_dy_t = {}\n",
    "    Pwr_st_t = {}\n",
    "    Pwr_t = {}\n",
    "    Cost_t = {}\n",
    "    \n",
    "    for time in range(90000,113100,300):\n",
    "        Pwr_dy_t[time] = []\n",
    "        Pwr_st_t[time] = []\n",
    "        Pwr_t[time] = []\n",
    "        Cost_t[time] = []\n",
    "    \n",
    "    Price_t = [0.5, 0.5, 0.6, 0.6, 0.6, 0.7, 0.7, 0.6, 0.6, 0.8, 0.8, 0.8, 0.8]\n",
    "    totalCost = 0\n",
    "    totalPwr = 0\n",
    "    \n",
    "    for time in range(90000,115500,timeQ):\n",
    "        taskQueue_t = taskQueues[time]\n",
    "        myVmSpace = [100*[25],100*[40]]\n",
    "        #reinitialize VMs for new time\n",
    "        rejectQueue_t = roundRobin(taskQueue_t,taskInfo,myVmSpace)\n",
    "        if(rejectQueue_t != []):\n",
    "            rejectQueue.append(rejectQueue_t)\n",
    "        Pwr_t[time] = powerConsumption(myVmSpace)\n",
    "        totalPwr = totalPwr + Pwr_t[time]\n",
    "        prcIdx = int((time - 90000)/3600)\n",
    "        Cost_t[time] = Price_t[prcIdx]*Pwr_t[time]\n",
    "        totalCost = totalCost + Cost_t[time]\n",
    "            \n",
    "    np.save('VMs_2.npy',myVmSpace)\n",
    "                \n",
    "    print(\"Number of rejected tasks is: {}\".format(len(rejectQueue)))\n",
    "    #print out the number of tasks that were rejected by the VMs\n",
    "    print(\"Total power use of tasks is: {}\".format(totalPwr))\n",
    "    print(\"Total cost of tasks is: {}\".format(totalCost))\n",
    "    \n",
    "    if(rejectQueue != []):\n",
    "        np.save('taskReject_2.npy',rejectQueue)\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1ad66-dcee-47bd-9412-fcda95702d3c",
   "metadata": {},
   "source": [
    "# Program Description\n",
    "\n",
    "The both programs have the same structure and can be divided into three steps: generating the task queue for each time quantum, running the round robin algorithm for each time quantum, and calculating the cost of the scheduled tasks. \n",
    "\n",
    "The task queues are generated for all time quantums before the round robin algorithm allocates the tasks to VMs. For each time quantum, the task queue-generating algorithmchecks if the task is ready at that time. If it is, the task is added to the queue for that time. If the task lasts multiple time quantums, then it is added to the queue of the following time quantums until it's spread over enough time quantums that it will be able to complete. However, if a task is not ready at the current time, the time is incrimented and the steps are repeated to fill the next task queue. \n",
    "\n",
    "Then, for each time quantum, the round robin alogorithm runs on the task queue for that time. The round robin algorithm will then allocated as many tasks as possible to the available VMs. For each task, the algorithm checks if the next available VM can fit those tasks. If so, then the task is allocated and the CPU and MEM space it uses is removed from the available space. Otherwise, the algorithm goes through all other VMs to see if it can fit in their spaces. If so, it is allocated to that VM. If the task cannot fit in any VM, it is appended to the reject queue.\n",
    "\n",
    "At each time quantum, the powerConsumption algorithm then calculates the power used by the VMs. The power for each VM is calculated as the sum of the dynamic and static powers for that VM. The power for each VM is then summed to get the total power consumed at that time. This total is then returned to the main program. \n",
    "\n",
    "The main program will multiply the power at each time by a constant dependent on that time to get the cost at that time. The power and cost can then be summed across all times. This produces the total power and cost used by the tasks when allocated using RR. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
