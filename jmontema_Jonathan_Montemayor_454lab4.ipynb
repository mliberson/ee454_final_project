{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c20341-8f8a-4687-a517-8f26870667c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "df = pd.read_csv('google-cluster-data-1.csv',sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ddf29f-b01b-46b3-bcb3-c1f6ad642155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3535029 tasks\n"
     ]
    }
   ],
   "source": [
    "print(str(len(df)) + \" tasks\")\n",
    "np.save(\"taskID.npy\", df[\"TaskID\"])\n",
    "np.save(\"taskCPU.npy\", df[\"NrmlTaskCores\"])\n",
    "np.save(\"taskMEM.npy\", df[\"NrmlTaskMem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05979678",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time_arr = []\n",
    "subtasks = 0\n",
    "quantum = 300\n",
    "for task in df.itertuples():\n",
    "    taskID = task.TaskID\n",
    "    burstTime = ((taskID%2)+1)*quantum\n",
    "    exec_time_arr.append(burstTime)\n",
    "    subtasks += burstTime / quantum\n",
    "\n",
    "exec_time_frame = pd.DataFrame({'ExecutionTime': exec_time_arr})\n",
    "df = df.join(exec_time_frame)\n",
    "# From https://stackoverflow.com/questions/20602947/append-column-to-pandas-dataframe\n",
    "\n",
    "np.save(\"exe_time_1.npy\", df[\"ExecutionTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8581a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5298274.0\n"
     ]
    }
   ],
   "source": [
    "print(subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a20c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"Time\"])\n",
    "\n",
    "# Sort by time just in case the times are not sorted\n",
    "# From https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html\n",
    "\n",
    "times = list(dict.fromkeys(df[\"Time\"].values)) # Removes duplicates from list while maintaining order\n",
    "# From https://datagy.io/python-remove-duplicates-from-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae0da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-2582b9b00fed>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  task[\"ExecutionTime\"] = quantum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5295934\n"
     ]
    }
   ],
   "source": [
    "prices = [0.5, 0.5, 0.6, 0.6, 0.6, 0.7, 0.7, 0.6, 0.6, 0.8, 0.8, 0.8, 0.8]\n",
    "\n",
    "def RR(task_queue, vms):\n",
    "    vms = np.array([[np.float64(7), np.float64(11)]])\n",
    "    vms = np.repeat(vms, repeats=100, axis=0)\n",
    "    vm_id = 0\n",
    "    reject_queue = []\n",
    "    for task in task_queue:\n",
    "        cpu_task = task.NrmlTaskCores\n",
    "        mem_task = task.NrmlTaskMem\n",
    "        cpu_vm = vms[vm_id][0]\n",
    "        mem_vm = vms[vm_id][1]\n",
    "        if cpu_task <= cpu_vm and mem_task <= mem_vm:\n",
    "            cpu_vm = cpu_vm - cpu_task\n",
    "            vms[vm_id][0] = cpu_vm\n",
    "            mem_vm = mem_vm - mem_task\n",
    "            vms[vm_id][1] = mem_vm\n",
    "        else:\n",
    "            nxt_vm = (vm_id + 1) % 100\n",
    "            found = False\n",
    "            while nxt_vm != vm_id:\n",
    "                cpu_nxt_vm = vms[nxt_vm][0]\n",
    "                mem_nxt_vm = vms[nxt_vm][1]\n",
    "                if cpu_task <= cpu_nxt_vm and mem_task <= mem_nxt_vm:\n",
    "                    cpu_nxt_vm = cpu_nxt_vm - cpu_task\n",
    "                    vms[nxt_vm][0] = cpu_nxt_vm\n",
    "                    mem_nxt_vm = mem_nxt_vm - mem_task\n",
    "                    vms[nxt_vm][1] = mem_nxt_vm\n",
    "                    found = True\n",
    "                    break\n",
    "                nxt_vm = (nxt_vm + 1) % 100\n",
    "            if not found:\n",
    "                reject_queue.append(task.TaskID)\n",
    "        vm_id = (vm_id + 1) % 100\n",
    "    \n",
    "    return reject_queue, vms\n",
    "\n",
    "def energy_consumption(vms, c, threshold, a, b):\n",
    "    Pwr_ttl_t = 0\n",
    "    for i in range(len(vms)):\n",
    "        used_cpu = vms[i][0]\n",
    "        cpu_cap = df[\"NrmlTaskCores\"][i]\n",
    "        Ur_m_t = 0\n",
    "        if cpu_cap > 0:\n",
    "            Ur_m_t = used_cpu / cpu_cap\n",
    "        Pwr_m_st_t = c if Ur_m_t > 0 else 0\n",
    "        Pwr_m_dy_t = None\n",
    "        if Ur_m_t < threshold:\n",
    "            Pwr_m_dy_t = Ur_m_t * a\n",
    "        else:\n",
    "            Pwr_m_dy_t = threshold * a + ((Ur_m_t - threshold) ** 2) * b\n",
    "        Pwr_m_t = Pwr_m_st_t + Pwr_m_dy_t\n",
    "        Pwr_ttl_t += Pwr_m_t\n",
    "    return Pwr_ttl_t\n",
    "\n",
    "def cost(Pwr_ttl_t, t, offset):\n",
    "    price_idx = (math.floor(t - offset))/3600\n",
    "    price = prices[int(price_idx)]\n",
    "    total_cost_t = price * Pwr_ttl_t\n",
    "    return total_cost_t\n",
    "\n",
    "curr_task_id = 0\n",
    "subtasks = 0\n",
    "excess_burst_queue = []\n",
    "all_reject_queue = []\n",
    "vms = []\n",
    "Pwr_ttl_all_t = 0\n",
    "total_cost_all_t = 0\n",
    "for t in times:\n",
    "    task_queue = copy.deepcopy(excess_burst_queue)\n",
    "    excess_burst_queue = []\n",
    "    for task in task_queue:\n",
    "        burst_time = task.ExecutionTime\n",
    "        if burst_time > quantum:\n",
    "            copied_task = task.copy()\n",
    "            copied_task[\"ExecutionTime\"] = burst_time - quantum\n",
    "            excess_burst_queue.append(copied_task)\n",
    "            task[\"ExecutionTime\"] = quantum\n",
    "        subtasks += 1\n",
    "    while curr_task_id < len(df) and df[\"Time\"][curr_task_id] == t:\n",
    "        task = df.loc[curr_task_id]\n",
    "        burst_time = task.ExecutionTime\n",
    "        if burst_time > quantum:\n",
    "            copied_task = task.copy()\n",
    "            # Make deep copy of task for use in the next task queue https://www.programiz.com/python-programming/shallow-deep-copy\n",
    "            copied_task[\"ExecutionTime\"] = burst_time - quantum\n",
    "            excess_burst_queue.append(copied_task)\n",
    "            task[\"ExecutionTime\"] = quantum\n",
    "        task_queue.append(task)\n",
    "        # Accessing single row by index: https://thispointer.com/select-rows-columns-by-name-or-index-in-dataframe-using-loc-iloc-python-pandas/\n",
    "        subtasks += 1\n",
    "        curr_task_id += 1\n",
    "    (reject_queue, vms) = RR(task_queue, vms)\n",
    "    all_reject_queue += reject_queue\n",
    "    Pwr_ttl_t = energy_consumption(vms, 5, 0.5, 100, 200)\n",
    "    Pwr_ttl_all_t += Pwr_ttl_t\n",
    "    total_cost_all_t += cost(Pwr_ttl_t, t, 90000)\n",
    "\n",
    "print(subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930f2e87-3d67-4216-8106-4b6af4f1a121",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rejections\n"
     ]
    }
   ],
   "source": [
    "if len(all_reject_queue) > 0:\n",
    "    np.save(\"taskReject_1.npy\", all_reject_queue)\n",
    "np.save(\"VMs_1.npy\", vms)\n",
    "print(str(len(all_reject_queue)) + \" rejections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e903956-736e-4b18-ad7f-c1699d2e3cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total power consumption: 136012545681.75362\n",
      "Total cost: 78238209969.12415\n"
     ]
    }
   ],
   "source": [
    "print(\"Total power consumption: \" + str(Pwr_ttl_all_t))\n",
    "print(\"Total cost: \" + str(total_cost_all_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd8371a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "df2 = pd.read_csv('google-cluster-data-1.csv',sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f6cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3535029 tasks\n"
     ]
    }
   ],
   "source": [
    "print(str(len(df2)) + \" tasks\")\n",
    "np.save(\"taskID_2.npy\", df2[\"TaskID\"])\n",
    "np.save(\"taskCPU_2.npy\", df2[\"NrmlTaskCores\"])\n",
    "np.save(\"taskMEM_2.npy\", df2[\"NrmlTaskMem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb776b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time_arr = []\n",
    "subtasks = 0\n",
    "quantum = 300\n",
    "for task in df2.itertuples():\n",
    "    taskID = task.TaskID\n",
    "    burstTime = ((taskID%10)+1)*quantum\n",
    "    exec_time_arr.append(burstTime)\n",
    "    subtasks += burstTime / quantum\n",
    "\n",
    "exec_time_frame = pd.DataFrame({'ExecutionTime': exec_time_arr})\n",
    "df2 = df2.join(exec_time_frame)\n",
    "# From https://stackoverflow.com/questions/20602947/append-column-to-pandas-dataframe\n",
    "\n",
    "np.save(\"exe_time_2.npy\", df2[\"ExecutionTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d93ddce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19472018.0\n"
     ]
    }
   ],
   "source": [
    "print(subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5aa540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_values(by=[\"Time\"])\n",
    "\n",
    "# Sort by time just in case the times are not sorted\n",
    "# From https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html\n",
    "\n",
    "times = list(dict.fromkeys(df2[\"Time\"].values)) # Removes duplicates from list while maintaining order\n",
    "# From https://datagy.io/python-remove-duplicates-from-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0144576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-8f7b3b834389>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  task[\"ExecutionTime\"] = quantum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18883760\n"
     ]
    }
   ],
   "source": [
    "prices = [0.5, 0.5, 0.6, 0.6, 0.6, 0.7, 0.7, 0.6, 0.6, 0.8, 0.8, 0.8, 0.8]\n",
    "\n",
    "def RR(task_queue, vms):\n",
    "    vms = np.array([[np.float64(25), np.float64(40)]])\n",
    "    vms = np.repeat(vms, repeats=100, axis=0)\n",
    "    vm_id = 0\n",
    "    reject_queue = []\n",
    "    for task in task_queue:\n",
    "        cpu_task = task.NrmlTaskCores\n",
    "        mem_task = task.NrmlTaskMem\n",
    "        cpu_vm = vms[vm_id][0]\n",
    "        mem_vm = vms[vm_id][1]\n",
    "        if cpu_task <= cpu_vm and mem_task <= mem_vm:\n",
    "            cpu_vm = cpu_vm - cpu_task\n",
    "            vms[vm_id][0] = cpu_vm\n",
    "            mem_vm = mem_vm - mem_task\n",
    "            vms[vm_id][1] = mem_vm\n",
    "        else:\n",
    "            nxt_vm = (vm_id + 1) % 100\n",
    "            found = False\n",
    "            while nxt_vm != vm_id:\n",
    "                cpu_nxt_vm = vms[nxt_vm][0]\n",
    "                mem_nxt_vm = vms[nxt_vm][1]\n",
    "                if cpu_task <= cpu_nxt_vm and mem_task <= mem_nxt_vm:\n",
    "                    cpu_nxt_vm = cpu_nxt_vm - cpu_task\n",
    "                    vms[nxt_vm][0] = cpu_nxt_vm\n",
    "                    mem_nxt_vm = mem_nxt_vm - mem_task\n",
    "                    vms[nxt_vm][1] = mem_nxt_vm\n",
    "                    found = True\n",
    "                    break\n",
    "                nxt_vm = (nxt_vm + 1) % 100\n",
    "            if not found:\n",
    "                reject_queue.append(task.TaskID)\n",
    "        vm_id = (vm_id + 1) % 100\n",
    "    \n",
    "    return reject_queue, vms\n",
    "\n",
    "def energy_consumption(vms, c, threshold, a, b):\n",
    "    Pwr_ttl_t = 0\n",
    "    for i in range(len(vms)):\n",
    "        used_cpu = vms[i][0]\n",
    "        cpu_cap = df2[\"NrmlTaskCores\"][i]\n",
    "        Ur_m_t = 0\n",
    "        if cpu_cap > 0:\n",
    "            Ur_m_t = used_cpu / cpu_cap\n",
    "        Pwr_m_st_t = c if Ur_m_t > 0 else 0\n",
    "        Pwr_m_dy_t = None\n",
    "        if Ur_m_t < threshold:\n",
    "            Pwr_m_dy_t = Ur_m_t * a\n",
    "        else:\n",
    "            Pwr_m_dy_t = threshold * a + ((Ur_m_t - threshold) ** 2) * b\n",
    "        Pwr_m_t = Pwr_m_st_t + Pwr_m_dy_t\n",
    "        Pwr_ttl_t += Pwr_m_t\n",
    "    return Pwr_ttl_t\n",
    "\n",
    "def cost(Pwr_ttl_t, t, offset):\n",
    "    price_idx = (math.floor(t - offset))/3600\n",
    "    price = prices[int(price_idx)]\n",
    "    total_cost_t = price * Pwr_ttl_t\n",
    "    return total_cost_t\n",
    "\n",
    "curr_task_id = 0\n",
    "subtasks = 0\n",
    "excess_burst_queue = []\n",
    "all_reject_queue = []\n",
    "vms = []\n",
    "Pwr_ttl_all_t = 0\n",
    "total_cost_all_t = 0\n",
    "for t in times:\n",
    "    task_queue = copy.deepcopy(excess_burst_queue)\n",
    "    excess_burst_queue = []\n",
    "    for task in task_queue:\n",
    "        burst_time = task.ExecutionTime\n",
    "        if burst_time > quantum:\n",
    "            copied_task = task.copy()\n",
    "            copied_task[\"ExecutionTime\"] = burst_time - quantum\n",
    "            excess_burst_queue.append(copied_task)\n",
    "            task[\"ExecutionTime\"] = quantum\n",
    "        subtasks += 1\n",
    "    while curr_task_id < len(df2) and df2[\"Time\"][curr_task_id] == t:\n",
    "        task = df2.loc[curr_task_id]\n",
    "        burst_time = task.ExecutionTime\n",
    "        if burst_time > quantum:\n",
    "            copied_task = task.copy()\n",
    "            # Make deep copy of task for use in the next task queue https://www.programiz.com/python-programming/shallow-deep-copy\n",
    "            copied_task[\"ExecutionTime\"] = burst_time - quantum\n",
    "            excess_burst_queue.append(copied_task)\n",
    "            task[\"ExecutionTime\"] = quantum\n",
    "        task_queue.append(task)\n",
    "        # Accessing single row by index: https://thispointer.com/select-rows-columns-by-name-or-index-in-dataframe-using-loc-iloc-python-pandas/\n",
    "        subtasks += 1\n",
    "        curr_task_id += 1\n",
    "    (reject_queue, vms) = RR(task_queue, vms)\n",
    "    all_reject_queue += reject_queue\n",
    "    Pwr_ttl_t = energy_consumption(vms, 5, 0.9, 100, 200)\n",
    "    Pwr_ttl_all_t += Pwr_ttl_t\n",
    "    total_cost_all_t += cost(Pwr_ttl_t, t, 90000)\n",
    "\n",
    "print(subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95ba9262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rejections\n"
     ]
    }
   ],
   "source": [
    "if len(all_reject_queue) > 0:\n",
    "    np.save(\"taskReject_2.npy\", all_reject_queue)\n",
    "np.save(\"VMs_2.npy\", vms)\n",
    "print(str(len(all_reject_queue)) + \" rejections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42bc22f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total power consumption: 2052874977445.3335\n",
      "Total cost: 1091755603619.9219\n"
     ]
    }
   ],
   "source": [
    "print(\"Total power consumption: \" + str(Pwr_ttl_all_t))\n",
    "print(\"Total cost: \" + str(total_cost_all_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d30ab9-43bb-44e3-ad0a-53dae75d583d",
   "metadata": {},
   "source": [
    "For a setup of 7 CPU units and 11 Mem units, we know that there are no rejections because after each time quantum, the VMs are reinitialized (i.e. the VMs are freeing up their space to make room for the incoming tasks). Thus, at each time quantum, the VMs just need to be able to service the incoming tasks (plus the old tasks that still need servicing as their execution time exceeds the time quantum). Because each task uses a small amount of CPU and mem and the number of tasks that the VMs need to service are now drastically lower, we thus know that there will be no rejections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c9279-81bd-43f1-9a16-29a61e307072",
   "metadata": {},
   "source": [
    "My code loads in the necessary CSV file into a df variable, and the number of tasks within the variable is printed out. Then, all the task IDs, task CPUs, and task memories are saved into their own respective files. Afterwards, I calculated the number of expected subtasks with burst time = ((TaskID % 2) + 1) * 300. Then, I sorted the tasks by time. For each time t, I constructed a task queue, pushing the tasks that have execution times that exceed the time quantum to the next task queue. I ran Round Robin on each task queue, reconstructing a 100x2 matrix (each CPU = 7 units, each Mem = 11 units) each time it was ran. I then calculated the energy consumption for all t for c = 5, dynamic power consumption threshold = 50%, a = 100, and b = 200. I also calculated the total cost for all t using a specified price array. I finally saved the VM matrix found after the last RR execution into VMs_1.npy.\n",
    "\n",
    "I then repeated the process for different parameters (Burst time = ((TaskID % 10) + 1) * 300, each CPU = 25 units, each Mem = 40 units Threshold = 90%). For a setup of 25 CPU units and 40 Mem units, there are no rejections for the same reasons listed above. \n",
    "\n",
    "NOTE: I was unable to fully run the second setup and get the necessary output files. Please run the second setup and get the output file to compare with the solution."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
