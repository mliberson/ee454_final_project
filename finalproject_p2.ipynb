{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "finalproject_p2_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j9u2W96r0DT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from functools import cmp_to_key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79GYw7ajr1j5",
        "outputId": "3bcd68b2-1d58-4b7b-a7a1-e9cea8c038db"
      },
      "source": [
        "#mount your google drive.\n",
        "#it will be visible in the file navigator on the left of this notebook\n",
        "#there should be a folder in your drive with your data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "y3m1fd-Hr0Dc",
        "outputId": "438dede6-755f-46fc-c946-698f5791371b"
      },
      "source": [
        "df = pd.read_csv('google-cluster-data-1.csv',sep=' ')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>ParentID</th>\n",
              "      <th>TaskID</th>\n",
              "      <th>JobType</th>\n",
              "      <th>NrmlTaskCores</th>\n",
              "      <th>NrmlTaskMem</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90000</td>\n",
              "      <td>757745334</td>\n",
              "      <td>1488529826</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90000</td>\n",
              "      <td>975992247</td>\n",
              "      <td>1488529821</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90000</td>\n",
              "      <td>1468458091</td>\n",
              "      <td>1488529832</td>\n",
              "      <td>1</td>\n",
              "      <td>0.021875</td>\n",
              "      <td>0.002353</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>90000</td>\n",
              "      <td>1460281235</td>\n",
              "      <td>1488529840</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>90000</td>\n",
              "      <td>1164728954</td>\n",
              "      <td>1488529835</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003125</td>\n",
              "      <td>0.001638</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3535024</th>\n",
              "      <td>112500</td>\n",
              "      <td>1487094655</td>\n",
              "      <td>1487103476</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3535025</th>\n",
              "      <td>112500</td>\n",
              "      <td>1461321601</td>\n",
              "      <td>1465612301</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3535026</th>\n",
              "      <td>112500</td>\n",
              "      <td>1487094655</td>\n",
              "      <td>1487097223</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3535027</th>\n",
              "      <td>112500</td>\n",
              "      <td>618817162</td>\n",
              "      <td>1485932004</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3535028</th>\n",
              "      <td>112500</td>\n",
              "      <td>1213243701</td>\n",
              "      <td>1349431592</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3535029 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Time    ParentID      TaskID  ...  NrmlTaskCores  NrmlTaskMem  Unnamed: 6\n",
              "0         90000   757745334  1488529826  ...       0.000000     0.031130         NaN\n",
              "1         90000   975992247  1488529821  ...       0.000000     0.000000         NaN\n",
              "2         90000  1468458091  1488529832  ...       0.021875     0.002353         NaN\n",
              "3         90000  1460281235  1488529840  ...       0.000000     0.000000         NaN\n",
              "4         90000  1164728954  1488529835  ...       0.003125     0.001638         NaN\n",
              "...         ...         ...         ...  ...            ...          ...         ...\n",
              "3535024  112500  1487094655  1487103476  ...       0.000000     0.000879         NaN\n",
              "3535025  112500  1461321601  1465612301  ...       0.000000     0.000879         NaN\n",
              "3535026  112500  1487094655  1487097223  ...       0.000000     0.000879         NaN\n",
              "3535027  112500   618817162  1485932004  ...       0.000000     0.000879         NaN\n",
              "3535028  112500  1213243701  1349431592  ...       0.000000     0.000879         NaN\n",
              "\n",
              "[3535029 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L10icmLr0Dp"
      },
      "source": [
        "def powerConsumption(myVmSpace):\n",
        "    c = 5\n",
        "    a = 100\n",
        "    b = 200\n",
        "    threshold = 0.5\n",
        "    \n",
        "    Pwr_dy = 0\n",
        "    Pwr_st = 0\n",
        "    Pwr = 0\n",
        "    \n",
        "    for core in myVmSpace[0]:\n",
        "        coreUsage = 1-core/5\n",
        "        if(coreUsage > 0):\n",
        "            Pwr_st = c\n",
        "        if(coreUsage < threshold):\n",
        "            Pwr_dy = a*coreUsage\n",
        "        else:\n",
        "            Pwr_dy = a*threshold + b*(coreUsage-threshold)*(coreUsage-threshold)\n",
        "        Pwr = Pwr + Pwr_dy + Pwr_st\n",
        "    return Pwr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0A_dq8Qr0D6"
      },
      "source": [
        "def compare(leftIdx, rightIdx):\n",
        "  if df['NrmlTaskCores'][leftIdx] < df['NrmlTaskCores'][rightIdx]:\n",
        "    return -1\n",
        "  elif df['NrmlTaskCores'][leftIdx] == df['NrmlTaskCores'][rightIdx]:\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "\n",
        "def generateTaskQueues():\n",
        "    taskQueues = {}\n",
        "    for time in range(90000,113400,300):\n",
        "        taskQueues[time] = []\n",
        "    time = 90000\n",
        "    for taskIdx in range(len(df['Time'])):\n",
        "        if(df['Time'][taskIdx] == time):\n",
        "          taskQueues[time].append(taskIdx)\n",
        "        else:\n",
        "          # Sort task queue for current time before going to next time\n",
        "          taskQueues[time] = sorted(taskQueues[time], key=cmp_to_key(compare), reverse=False)\n",
        "          time = time + 300\n",
        "          taskQueues[time].append(taskIdx)\n",
        "        \n",
        "    return taskQueues"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCggIgh-r0Df"
      },
      "source": [
        "## Append Execution Time and Turnaround Time information to dataframe\n",
        "* Add total execution time list to dataframe under key \"ExecutionTime\". A task queue is created for each time quantum for which tasks are allocated. Tasks are allocated to a given task queue based on their arrival time and remaining execution time. Therefore, total execution time is used to determine which task queues each task should be placed in.\n",
        "* Add columns to store the turnaround times for each version of the greedy algorithm (power, cost, round robin, and just the turnaround time)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBXCkgoSr0D7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5c633c-9898-4739-e98f-8f9bae41b958"
      },
      "source": [
        "exec_time_arr = []\n",
        "subtasks = 0\n",
        "quantum = 300\n",
        "rejectQueue = []\n",
        "burstTime = None\n",
        "for index,task in df.iterrows():\n",
        "    taskID = task[\"TaskID\"]\n",
        "    burstTime = ((taskID%2)+1)*quantum      # only two options for burst time\n",
        "    exec_time_arr.append(burstTime)\n",
        "    subtasks += burstTime / quantum\n",
        "\n",
        "time_dict = {\n",
        "    'ExecutionTime': exec_time_arr,\n",
        "    'TurnaroundTime_Power': [0]*len(df[\"Time\"]),\n",
        "    'TurnaroundTime_Cost': [0]*len(df[\"Time\"]),\n",
        "    'TurnaroundTime': [0]*len(df[\"Time\"]),\n",
        "    'TurnaroundTime_RR': [0]*len(df[\"Time\"])\n",
        "}\n",
        "for key in time_dict.keys():\n",
        "    df[key] = time_dict[key]\n",
        "print(\"Subtasks:\", subtasks)\n",
        "\n",
        "# Create power and cost dictionaries\n",
        "Pwr_t = {}\n",
        "Cost_t = {}\n",
        "\n",
        "Price_t = [0.5, 0.5, 0.6, 0.6, 0.6, 0.7, 0.7, 0.6, 0.6, 0.8, 0.8, 0.8, 0.8]\n",
        "\n",
        "for time in range(90000,113400,300): \n",
        "    Pwr_t[time] = []\n",
        "    Cost_t[time] = []\n",
        "\n",
        "taskQueues = generateTaskQueues()\n",
        "\n",
        "rejectQueue = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subtasks: 5298274.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x3jOcPjvP8P"
      },
      "source": [
        "## Round Robin Algorithm\n",
        "* Each subtask will be allocated to the next VM.\n",
        "* If a subtask can't fit inside the VM that it is assigned to, keep iterating through the VMs until you find one that can fit the subtask. If no VMs can fit the task, reject the subtask and all subsequent subtasks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuJrPbvgr0Dr"
      },
      "source": [
        "def RR(taskQueue, myVmSpace, currTime):\n",
        "               \n",
        "    VM_iter = 0\n",
        "    #will iterate through all possible starting VMs, increments by one each time\n",
        "    VM_jter = 0\n",
        "    #incrementer used when task does not fit in the first potentially available VM\n",
        "    \n",
        "    rejectQueue = []\n",
        "    nextTaskQueue = []    # becomes the remaining subtasks from the last part\n",
        "\n",
        "    time_quantum = 300\n",
        "               \n",
        "    for task_idx in taskQueue:\n",
        "        if(df['NrmlTaskCores'][task_idx] <= myVmSpace[0][VM_iter] and df['NrmlTaskMem'][task_idx] <= myVmSpace[1][VM_iter]):\n",
        "            #if the number of cores and memory space the task requires is less than the available for the VMS\n",
        "            #then we can allocate the task to the current VM\n",
        "            myVmSpace[0][VM_iter] -= df['NrmlTaskCores'][task_idx]\n",
        "            myVmSpace[1][VM_iter] -= df['NrmlTaskMem'][task_idx]\n",
        "            #now that the task is allocated, we have to update the amount of free CPU and memory space\n",
        "            finTime = currTime + time_quantum\n",
        "            startTime = df[\"Time\"][task_idx]\n",
        "            df[\"TurnaroundTime_RR\"][task_idx] = finTime - startTime\n",
        "             #if the task is longer than one time quantum, add it to the next time queue after it has been allocated the first time\n",
        "            if(df[\"ExecutionTime\"][task_idx] == 600 and df[\"Time\"][task_idx] == currTime):\n",
        "              nextTaskQueue.append(task_idx)\n",
        "            # Save turnaround time\n",
        "        else:\n",
        "            allocated = False\n",
        "            VM_jter = (VM_iter + 1) % 100\n",
        "            #move to the next VM\n",
        "            while(not allocated and VM_jter!=VM_iter):\n",
        "                #if it is allocated then don't keep looking\n",
        "                #if you've looked at all possible VMs and its not allocated, then it never will be so end loop\n",
        "                if(df['NrmlTaskCores'][task_idx] <= myVmSpace[0][VM_jter] and df['NrmlTaskMem'][task_idx] <= myVmSpace[1][VM_jter]):\n",
        "                    #if the number of cores and memory space the task requires is less than the available for the VMS\n",
        "                    #then we can allocate the task to the current VM\n",
        "                    myVmSpace[0][VM_jter] -= df['NrmlTaskCores'][task_idx]\n",
        "                    myVmSpace[1][VM_jter] -= df['NrmlTaskMem'][task_idx]\n",
        "                    #now that the task is allocated, we have to update the amount of free CPU and memory space\n",
        "                    allocated = True\n",
        "                    #allocate the task\n",
        "                    # Save turnaround time\n",
        "                    finTime = currTime + time_quantum\n",
        "                    startTime = df[\"Time\"][task_idx]\n",
        "                    df[\"TurnaroundTime_RR\"][task_idx] = finTime - startTime\n",
        "                    #if the task is longer than one time quantum, add it to the next time queue after it has been allocated the first time\n",
        "                    if(df[\"ExecutionTime\"][task_idx] == 600 and df[\"Time\"][task_idx] == currTime):\n",
        "                      nextTaskQueue.append(task_idx)\n",
        "                VM_jter = (VM_jter + 1) % 100\n",
        "                #move to the next VM\n",
        "            if(not allocated):\n",
        "                rejectQueue.append(df['TaskID'][task_idx])\n",
        "                #if the while loop finishes and the task is still not allocated\n",
        "                #then it cycled through all VMs and did not fit any, so it cannot be allocated and should be added to reject queue\n",
        "        VM_iter = (VM_iter + 1) % 100\n",
        "\n",
        "    return rejectQueue, myVmSpace, nextTaskQueue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxQdRUVut1Ho",
        "outputId": "137b75e9-c478-4a67-bcdb-e940bb87c88f"
      },
      "source": [
        "# Round Robin\n",
        "\n",
        "timeQ = 300\n",
        "\n",
        "rejectQueue = [] \n",
        "#queue of tasks that could not fit into any VM for all times\n",
        "rejectQueue_t = []\n",
        "\n",
        "# Pwr_dy_t = {}\n",
        "# Pwr_st_t = {}\n",
        "Pwr_t = {}\n",
        "Cost_t = {}\n",
        "\n",
        "for time in range(90000,113400,timeQ): # Go from 90000 to 113100 (113400 not included)\n",
        "    # Pwr_dy_t[time] = []\n",
        "    # Pwr_st_t[time] = []\n",
        "    Pwr_t[time] = []\n",
        "    Cost_t[time] = []\n",
        "\n",
        "Price_t = [0.5, 0.5, 0.6, 0.6, 0.6, 0.7, 0.7, 0.6, 0.6, 0.8, 0.8, 0.8, 0.8]\n",
        "totalCost = 0\n",
        "totalPwr = 0\n",
        "\n",
        "taskQueue_t = taskQueues[90000]\n",
        "for time in range(90000,113400,timeQ): # Go from 90000 to 113100 (113400 not included)\n",
        "    vms = [100*[5],100*[10]]\n",
        "    #reinitialize VMs for new time\n",
        "    rejectQueue_t, vms, nextTaskQueue = RR(taskQueue_t, vms, time)\n",
        "    if(time != 113100):\n",
        "      nextTaskQueue.extend(taskQueues[time+300])\n",
        "      taskQueue_t = nextTaskQueue\n",
        "    print(\"Finished running for time {}\".format(time))\n",
        "    if(rejectQueue_t != []):\n",
        "      rejectQueue.append(rejectQueue_t)\n",
        "      taskQueues[time]\n",
        "    Pwr_t[time] = powerConsumption(vms)\n",
        "    totalPwr += Pwr_t[time]\n",
        "    prcIdx = int((time - 90000)/3600)\n",
        "    Cost_t[time] = Price_t[prcIdx]*Pwr_t[time]\n",
        "    totalCost += Cost_t[time]\n",
        "\n",
        "print(\"Round Robin:\")\n",
        "print(\"\\tTotal power:\", totalPwr)\n",
        "print(\"\\tTotal cost: \", totalCost)\n",
        "\n",
        "turnaroundtime_sum = 0\n",
        "for index,task in df.iterrows():\n",
        "    turnaroundtime_sum += task.TurnaroundTime_RR\n",
        "avg_turnaroundtime = float(turnaroundtime_sum) / float(len(df)-len(rejectQueue))\n",
        "print(\"\\tAverage turnaround time:\", avg_turnaroundtime)\n",
        "\n",
        "print(\"\\t\" + str(len(rejectQueue)) + \" rejections\")\n",
        "if(rejectQueue != []):\n",
        "    np.save('taskReject_2_RR.npy',rejectQueue)\n",
        "\n",
        "vmFileName = \"VMs_2_RR.npy\"\n",
        "np.save(vmFileName, vms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished running for time 90000\n",
            "Finished running for time 90300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished running for time 90600\n",
            "Finished running for time 90900\n",
            "Finished running for time 91200\n",
            "Finished running for time 91500\n",
            "Finished running for time 91800\n",
            "Finished running for time 92100\n",
            "Finished running for time 92400\n",
            "Finished running for time 92700\n",
            "Finished running for time 93000\n",
            "Finished running for time 93300\n",
            "Finished running for time 93600\n",
            "Finished running for time 93900\n",
            "Finished running for time 94200\n",
            "Finished running for time 94500\n",
            "Finished running for time 94800\n",
            "Finished running for time 95100\n",
            "Finished running for time 95400\n",
            "Finished running for time 95700\n",
            "Finished running for time 96000\n",
            "Finished running for time 96300\n",
            "Finished running for time 96600\n",
            "Finished running for time 96900\n",
            "Finished running for time 97200\n",
            "Finished running for time 97500\n",
            "Finished running for time 97800\n",
            "Finished running for time 98100\n",
            "Finished running for time 98400\n",
            "Finished running for time 98700\n",
            "Finished running for time 99000\n",
            "Finished running for time 99300\n",
            "Finished running for time 99600\n",
            "Finished running for time 99900\n",
            "Finished running for time 100200\n",
            "Finished running for time 100500\n",
            "Finished running for time 100800\n",
            "Finished running for time 101100\n",
            "Finished running for time 101400\n",
            "Finished running for time 101700\n",
            "Finished running for time 102000\n",
            "Finished running for time 102300\n",
            "Finished running for time 102600\n",
            "Finished running for time 102900\n",
            "Finished running for time 103200\n",
            "Finished running for time 103500\n",
            "Finished running for time 103800\n",
            "Finished running for time 104100\n",
            "Finished running for time 104400\n",
            "Finished running for time 104700\n",
            "Finished running for time 105000\n",
            "Finished running for time 105300\n",
            "Finished running for time 105600\n",
            "Finished running for time 105900\n",
            "Finished running for time 106200\n",
            "Finished running for time 106500\n",
            "Finished running for time 106800\n",
            "Finished running for time 107100\n",
            "Finished running for time 107400\n",
            "Finished running for time 107700\n",
            "Finished running for time 108000\n",
            "Finished running for time 108300\n",
            "Finished running for time 108600\n",
            "Finished running for time 108900\n",
            "Finished running for time 109200\n",
            "Finished running for time 109500\n",
            "Finished running for time 109800\n",
            "Finished running for time 110100\n",
            "Finished running for time 110400\n",
            "Finished running for time 110700\n",
            "Finished running for time 111000\n",
            "Finished running for time 111300\n",
            "Finished running for time 111600\n",
            "Finished running for time 111900\n",
            "Finished running for time 112200\n",
            "Finished running for time 112500\n",
            "Finished running for time 112800\n",
            "Finished running for time 113100\n",
            "Round Robin:\n",
            "\tTotal power: 765310.7432812457\n",
            "\tTotal cost:  451545.5749062473\n",
            "\tAverage turnaround time: 441.6795003954788\n",
            "\t73 rejections\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QmMoYuir0Dm"
      },
      "source": [
        "# Returns whether or not a task can fit in a VM\n",
        "def powerVMAlloc(vms, task_idx, vm_idx, all_past_threshold):\n",
        "  can_fit = df['NrmlTaskCores'][task_idx] <= vms[0][vm_idx] and df['NrmlTaskMem'][task_idx] <= vms[1][vm_idx]\n",
        "  if all_past_threshold:\n",
        "    return can_fit\n",
        "  else:\n",
        "    dy_pwr_threshold = 0.5\n",
        "    \n",
        "    cpu = df['NrmlTaskCores'][task_idx]\n",
        "\n",
        "    # current vm calculation\n",
        "    cpu_cap = 5.0\n",
        "    ccr = float(vms[0][vm_idx]) - float(cpu) # current core remaining \n",
        "\n",
        "    usage_rate_curr = 1.0 - float(ccr/cpu_cap)   \n",
        "\n",
        "    return can_fit and usage_rate_curr < dy_pwr_threshold      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf_MvBFbr0Du"
      },
      "source": [
        "# Greedy Algorithm\n",
        "* This algorithm optimizes power/energy consumption, which will give us the optimal power. But it also will give us the optimal cost since cost depends on the power consumption of the VM.\n",
        "* Our algorithm works as so:\n",
        "1. For the given task queue at a specific time, optimize power consumption.\n",
        "2. We noticed that power consumption follows a linear relationship up until it exceeds the threshold. So we can assume that a VM filled up with subtasks below the threshold will have a total power consumption equal to if the subtasks were spread out among multiple VMs. With this in mind, we decided to modify our algorithm such that a single VM gets filled up with tasks until it is about to exceed the threshold. When this happens, we iterate to the next VM.\n",
        "3. If all the VMs have exceeded the threshold and there are still tasks to allocate, allocate the tasks to the VMs round robin style. This will still keep power optimized because we sorted the tasks for each time by their core usage. Another added benefit of sorting by core usage is that if a task can't fit into any VM, we can reject that task and all subsequent tasks for the time period (since they will have a core usage bigger than the task that couldn't fit in).\n",
        "4. Edge case: if a task with an execution time of 600 is rejected, we reject its subsequent subtask too (our nextTaskQueue implementation handles this. It only appends the subsequent subtask to the next task queue if the subtask at the current time is able to be allocated to a VM)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7lpUxrcr0Dv"
      },
      "source": [
        "def greedy(task_queue, vms, optIdentifier, currTime):\n",
        "    rejectQueue = []\n",
        "    nextTaskQueue = []\n",
        "    time_quantum = 300\n",
        "\n",
        "    all_past_threshold = False\n",
        "    vm_iter = 0\n",
        "    task_rejected = False\n",
        "    check = False\n",
        "\n",
        "    for task_idx in task_queue: \n",
        "        if task_rejected:\n",
        "          rejectQueue.append(task['TaskID'])\n",
        "          continue\n",
        "\n",
        "        if not all_past_threshold:\n",
        "          should_alloc = powerVMAlloc(vms,task_idx,vm_iter,all_past_threshold)\n",
        "          if not should_alloc and vm_iter == 99:\n",
        "            vm_iter = 0\n",
        "            all_past_threshold = True\n",
        "          elif not should_alloc and vm_iter < 99:\n",
        "            vm_iter += 1\n",
        "            vms[0][vm_iter] -= df['NrmlTaskCores'][task_idx]\n",
        "            vms[1][vm_iter] -= df['NrmlTaskMem'][task_idx]\n",
        "            #if the task is longer than one time quantum, add it to the next time queue after it has been allocated the first time\n",
        "            if(df[\"ExecutionTime\"][task_idx] == 600 and df[\"Time\"][task_idx] == currTime):\n",
        "              nextTaskQueue.append(task_idx)\n",
        "            startTime = df['Time'][task_idx]\n",
        "            exTime = df['ExecutionTime'][task_idx]\n",
        "            if currTime == startTime + exTime - time_quantum:\n",
        "              # Turnaround time is the curr time that the task finishes minus the arrival time\n",
        "              finishTime = currTime + time_quantum\n",
        "              turnaroundType = \"TurnaroundTime_Power\" if optIdentifier == \"power\" else \"TurnaroundTime_Cost\"\n",
        "              df[turnaroundType][task_idx] = finishTime - startTime\n",
        "          else:\n",
        "            vms[0][vm_iter] -= df['NrmlTaskCores'][task_idx]\n",
        "            vms[1][vm_iter] -= df['NrmlTaskMem'][task_idx]\n",
        "            #if the task is longer than one time quantum, add it to the next time queue after it has been allocated the first time\n",
        "            if(df[\"ExecutionTime\"][task_idx] == 600 and df[\"Time\"][task_idx] == currTime):\n",
        "              nextTaskQueue.append(task_idx)\n",
        "            startTime = df['Time'][task_idx]\n",
        "            exTime = df['ExecutionTime'][task_idx]\n",
        "            if currTime == startTime + exTime - time_quantum:\n",
        "              # Turnaround time is the curr time that the task finishes minus the arrival time\n",
        "              finishTime = currTime + time_quantum\n",
        "              turnaroundType = \"TurnaroundTime_Power\" if optIdentifier == \"power\" else \"TurnaroundTime_Cost\"\n",
        "              df[turnaroundType][task_idx] = finishTime - startTime\n",
        "\n",
        "        if all_past_threshold:\n",
        "          should_alloc = powerVMAlloc(vms,task_idx,vm_iter,all_past_threshold)\n",
        "          if not should_alloc:\n",
        "            vm_jter = (vm_iter + 1) % 100\n",
        "            should_alloc = False\n",
        "            while vm_jter != vm_iter:\n",
        "              should_alloc = powerVMAlloc(vms,task_idx,vm_jter,all_past_threshold)\n",
        "              if should_alloc:\n",
        "                vms[0][vm_jter] -= df['NrmlTaskCores'][task_idx]\n",
        "                vms[1][vm_jter] -= df['NrmlTaskMem'][task_idx]\n",
        "                #if the task is longer than one time quantum, add it to the next time queue after it has been allocated the first time\n",
        "                if(df[\"ExecutionTime\"][task_idx] == 600 and df[\"Time\"][task_idx] == currTime):\n",
        "                  nextTaskQueue.append(task_idx)\n",
        "                vm_iter = (vm_iter + 1) % 100\n",
        "                startTime = df['Time'][task_idx]\n",
        "                exTime = df['ExecutionTime'][task_idx]\n",
        "                if currTime == startTime + exTime - time_quantum:\n",
        "                  # Turnaround time is the curr time that the task finishes minus the arrival time\n",
        "                  finishTime = currTime + time_quantum\n",
        "                  turnaroundType = \"TurnaroundTime_Power\" if optIdentifier == \"power\" else \"TurnaroundTime_Cost\"\n",
        "                  df[turnaroundType][task_idx] = finishTime - startTime\n",
        "                break\n",
        "              vm_jter = (vm_jter + 1) % 100\n",
        "            if not should_alloc:\n",
        "              rejectQueue.append(task['TaskID'])\n",
        "              task_rejected = True\n",
        "              continue\n",
        "          else:\n",
        "            vms[0][vm_iter] -= df['NrmlTaskCores'][task_idx]\n",
        "            vms[1][vm_iter] -= df['NrmlTaskMem'][task_idx]\n",
        "            #if the task is longer than one time quantum, add it to the next time queue after it has been allocated the first time\n",
        "            if(df[\"ExecutionTime\"][task_idx] == 600 and df[\"Time\"][task_idx] == currTime):\n",
        "              nextTaskQueue.append(task_idx)\n",
        "            vm_iter = (vm_iter + 1) % 100\n",
        "            startTime = df['Time'][task_idx]\n",
        "            exTime = df['ExecutionTime'][task_idx]\n",
        "            if currTime == startTime + exTime - time_quantum:\n",
        "              # Turnaround time is the curr time that the task finishes minus the arrival time\n",
        "              finishTime = currTime + time_quantum\n",
        "              turnaroundType = \"TurnaroundTime_Power\" if optIdentifier == \"power\" else \"TurnaroundTime_Cost\"\n",
        "              df[turnaroundType][task_idx] = finishTime - startTime\n",
        "    return rejectQueue, vms, nextTaskQueue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pyjslREr0D9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5639a4e-f2bb-4a99-bad2-d3e4f411ad02"
      },
      "source": [
        "#power optimization\n",
        "rejectQueue = []\n",
        "totalPwr = 0\n",
        "totalCost = 0\n",
        "\n",
        "taskQueue_t = taskQueues[90000]\n",
        "for time in range(90000,113400,300): #90000 - 113100 (113400 not included)\n",
        "    vms = [100*[5.0],100*[10.0]]\n",
        "\n",
        "    #reinitialize VMs for new time\n",
        "    rejectQueue_t, vms_t, nextTaskQueue = greedy(taskQueue_t,vms,\"power\", time)\n",
        "    print(\"Finished running for time {}\".format(time))\n",
        "    if(time != 113100):\n",
        "      nextTaskQueue.extend(taskQueues[time+300])\n",
        "      taskQueue_t = nextTaskQueue\n",
        "    if(rejectQueue_t != []):\n",
        "      rejectQueue.extend(rejectQueue_t)\n",
        "    Pwr_t[time] = powerConsumption(vms_t)\n",
        "    totalPwr = totalPwr + Pwr_t[time]\n",
        "    prcIdx = int((time - 90000)/3600)\n",
        "    Cost_t[time] = Price_t[prcIdx]*Pwr_t[time]\n",
        "    totalCost = totalCost + Cost_t[time]\n",
        "\n",
        "print(\"Power optimization:\")\n",
        "print(\"\\tTotal power:\", totalPwr)\n",
        "print(\"\\tTotal cost: \", totalCost)\n",
        "\n",
        "turnaroundtime_sum = 0\n",
        "for index,task in df.iterrows():\n",
        "    turnaroundtime_sum += task.TurnaroundTime_Power\n",
        "avg_turnaroundtime = float(turnaroundtime_sum) / float(len(df)-len(rejectQueue))\n",
        "print(\"\\tAverage turnaround time:\", avg_turnaroundtime)\n",
        "\n",
        "print(\"\\t\" + str(len(rejectQueue)) + \" rejections\")\n",
        "if (len(rejectQueue) > 0):\n",
        "    rejectFileName = \"taskReject_2_power.npy\"\n",
        "    np.save(rejectFileName, rejectQueue)\n",
        "vmFileName = \"VMs_2_power.npy\"\n",
        "np.save(vmFileName, vms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished running for time 90000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished running for time 90300\n",
            "Finished running for time 90600\n",
            "Finished running for time 90900\n",
            "Finished running for time 91200\n",
            "Finished running for time 91500\n",
            "Finished running for time 91800\n",
            "Finished running for time 92100\n",
            "Finished running for time 92400\n",
            "Finished running for time 92700\n",
            "Finished running for time 93000\n",
            "Finished running for time 93300\n",
            "Finished running for time 93600\n",
            "Finished running for time 93900\n",
            "Finished running for time 94200\n",
            "Finished running for time 94500\n",
            "Finished running for time 94800\n",
            "Finished running for time 95100\n",
            "Finished running for time 95400\n",
            "Finished running for time 95700\n",
            "Finished running for time 96000\n",
            "Finished running for time 96300\n",
            "Finished running for time 96600\n",
            "Finished running for time 96900\n",
            "Finished running for time 97200\n",
            "Finished running for time 97500\n",
            "Finished running for time 97800\n",
            "Finished running for time 98100\n",
            "Finished running for time 98400\n",
            "Finished running for time 98700\n",
            "Finished running for time 99000\n",
            "Finished running for time 99300\n",
            "Finished running for time 99600\n",
            "Finished running for time 99900\n",
            "Finished running for time 100200\n",
            "Finished running for time 100500\n",
            "Finished running for time 100800\n",
            "Finished running for time 101100\n",
            "Finished running for time 101400\n",
            "Finished running for time 101700\n",
            "Finished running for time 102000\n",
            "Finished running for time 102300\n",
            "Finished running for time 102600\n",
            "Finished running for time 102900\n",
            "Finished running for time 103200\n",
            "Finished running for time 103500\n",
            "Finished running for time 103800\n",
            "Finished running for time 104100\n",
            "Finished running for time 104400\n",
            "Finished running for time 104700\n",
            "Finished running for time 105000\n",
            "Finished running for time 105300\n",
            "Finished running for time 105600\n",
            "Finished running for time 105900\n",
            "Finished running for time 106200\n",
            "Finished running for time 106500\n",
            "Finished running for time 106800\n",
            "Finished running for time 107100\n",
            "Finished running for time 107400\n",
            "Finished running for time 107700\n",
            "Finished running for time 108000\n",
            "Finished running for time 108300\n",
            "Finished running for time 108600\n",
            "Finished running for time 108900\n",
            "Finished running for time 109200\n",
            "Finished running for time 109500\n",
            "Finished running for time 109800\n",
            "Finished running for time 110100\n",
            "Finished running for time 110400\n",
            "Finished running for time 110700\n",
            "Finished running for time 111000\n",
            "Finished running for time 111300\n",
            "Finished running for time 111600\n",
            "Finished running for time 111900\n",
            "Finished running for time 112200\n",
            "Finished running for time 112500\n",
            "Finished running for time 112800\n",
            "Finished running for time 113100\n",
            "Power optimization:\n",
            "\tTotal power: 499762.2386718726\n",
            "\tTotal cost:  295668.78907812346\n",
            "\tAverage turnaround time: 449.59484375631075\n",
            "\t341076 rejections\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoQmAIB_r0D-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3425c1ad-9fe4-4a79-dab6-c62d6fc4608b"
      },
      "source": [
        "#cost optimization\n",
        "totalPwr = 0\n",
        "totalCost = 0\n",
        "rejectQueue = []\n",
        "taskQueue_t = taskQueues[90000]\n",
        "for time in range(90000,113400,300): #90000 - 113100 (113400 not included)\n",
        "    vms = [100*[5],100*[10]]\n",
        "    #reinitialize VMs for new time\n",
        "    rejectQueue_t, vms_t, nextTaskQueue = greedy(taskQueue_t,vms,\"cost\",time)\n",
        "    print(\"Finished running for time {}\".format(time))\n",
        "    if(time != 113100):\n",
        "      nextTaskQueue.extend(taskQueues[time+300])\n",
        "      taskQueue_t = nextTaskQueue\n",
        "    if(rejectQueue_t != []):\n",
        "        rejectQueue.extend(rejectQueue_t)\n",
        "    Pwr_t[time] = powerConsumption(vms_t)\n",
        "    totalPwr = totalPwr + Pwr_t[time]\n",
        "    prcIdx = int((time - 90000)/3600)\n",
        "    Cost_t[time] = Price_t[prcIdx]*Pwr_t[time]\n",
        "    totalCost = totalCost + Cost_t[time]\n",
        "\n",
        "print(\"Cost optimization:\")\n",
        "print(\"\\tTotal power:\", totalPwr)\n",
        "print(\"\\tTotal cost: \", totalCost)\n",
        "\n",
        "turnaroundtime_sum = 0\n",
        "for index,task in df.iterrows():\n",
        "    turnaroundtime_sum += task.TurnaroundTime_Cost\n",
        "avg_turnaroundtime = float(turnaroundtime_sum) / float(len(df)-len(rejectQueue))\n",
        "print(\"\\tAverage turnaround time:\", avg_turnaroundtime)\n",
        "\n",
        "print(\"\\t\" + str(len(rejectQueue)) + \" rejections\")\n",
        "if (len(rejectQueue) > 0):\n",
        "    rejectFileName = \"taskReject_2_cost.npy\"\n",
        "    np.save(rejectFileName, rejectQueue)\n",
        "vmFileName = \"VMs_2_cost.npy\"\n",
        "np.save(vmFileName, vms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished running for time 90000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished running for time 90300\n",
            "Finished running for time 90600\n",
            "Finished running for time 90900\n",
            "Finished running for time 91200\n",
            "Finished running for time 91500\n",
            "Finished running for time 91800\n",
            "Finished running for time 92100\n",
            "Finished running for time 92400\n",
            "Finished running for time 92700\n",
            "Finished running for time 93000\n",
            "Finished running for time 93300\n",
            "Finished running for time 93600\n",
            "Finished running for time 93900\n",
            "Finished running for time 94200\n",
            "Finished running for time 94500\n",
            "Finished running for time 94800\n",
            "Finished running for time 95100\n",
            "Finished running for time 95400\n",
            "Finished running for time 95700\n",
            "Finished running for time 96000\n",
            "Finished running for time 96300\n",
            "Finished running for time 96600\n",
            "Finished running for time 96900\n",
            "Finished running for time 97200\n",
            "Finished running for time 97500\n",
            "Finished running for time 97800\n",
            "Finished running for time 98100\n",
            "Finished running for time 98400\n",
            "Finished running for time 98700\n",
            "Finished running for time 99000\n",
            "Finished running for time 99300\n",
            "Finished running for time 99600\n",
            "Finished running for time 99900\n",
            "Finished running for time 100200\n",
            "Finished running for time 100500\n",
            "Finished running for time 100800\n",
            "Finished running for time 101100\n",
            "Finished running for time 101400\n",
            "Finished running for time 101700\n",
            "Finished running for time 102000\n",
            "Finished running for time 102300\n",
            "Finished running for time 102600\n",
            "Finished running for time 102900\n",
            "Finished running for time 103200\n",
            "Finished running for time 103500\n",
            "Finished running for time 103800\n",
            "Finished running for time 104100\n",
            "Finished running for time 104400\n",
            "Finished running for time 104700\n",
            "Finished running for time 105000\n",
            "Finished running for time 105300\n",
            "Finished running for time 105600\n",
            "Finished running for time 105900\n",
            "Finished running for time 106200\n",
            "Finished running for time 106500\n",
            "Finished running for time 106800\n",
            "Finished running for time 107100\n",
            "Finished running for time 107400\n",
            "Finished running for time 107700\n",
            "Finished running for time 108000\n",
            "Finished running for time 108300\n",
            "Finished running for time 108600\n",
            "Finished running for time 108900\n",
            "Finished running for time 109200\n",
            "Finished running for time 109500\n",
            "Finished running for time 109800\n",
            "Finished running for time 110100\n",
            "Finished running for time 110400\n",
            "Finished running for time 110700\n",
            "Finished running for time 111000\n",
            "Finished running for time 111300\n",
            "Finished running for time 111600\n",
            "Finished running for time 111900\n",
            "Finished running for time 112200\n",
            "Finished running for time 112500\n",
            "Finished running for time 112800\n",
            "Finished running for time 113100\n",
            "Cost optimization:\n",
            "\tTotal power: 499762.2386718726\n",
            "\tTotal cost:  295668.78907812346\n",
            "\tAverage turnaround time: 449.59484375631075\n",
            "\t341076 rejections\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usNjLtGyr0D1"
      },
      "source": [
        "# Shortest Job First Algorithm\n",
        "The Shortest Job First algorithm is optimal for waiting time and thus turnaround time (assuming task execution time is time-invariant). \n",
        "# There are several steps involved in implementing SJF. \n",
        "1. Create a dictionary containing all vms for all times for which the algorithm will be run. Creating all vms at once allows us to allocate a process to VMs for all of its execution time, not just the current time quantum. \n",
        "2. Iterate through the task queue once for all tasks with an execution time of 300. Keep allocating to the same VM until the VM gets filled, in which case we move on to the next VM.\n",
        "3. Iterate thorugh the task queue again for all tasks with an execution time of 600. Repeat the same process of allocating to the same VM. Forcing the 600 runtime tasks to wait until the 300 runtime tasks are allocated gives those 300 runtime tasks priority, which makes the algorithm SJF. \n",
        "4. If all the VMs get filled, we know to reject all subsequent tasks for the current time because the tasks are sorted in ascending order of VM usage. \n",
        "5. Return the reject queue and vm dictionary.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPVDiF4Mr0D3"
      },
      "source": [
        "def sjf(time_params, time_quantum, vm_size, taskQueues):\n",
        "    vms = {} #vms for all possible times\n",
        "    rejectQueue = []\n",
        "    # Reinitialize Turnaround times\n",
        "    # df[\"TurnaroundTime\"] = [0]*len(df)\n",
        "    # Worst case:\n",
        "    # If setup == 1, vms will be used at the max arrival time + time quantum * 2 (b/c burst time max = 600 and time quantum = 300)\n",
        "    # If setup == 2, max time for vms will be max arrival time + time quantum * 10 (b/c burst time max = 3000 and time quantum = 300)\n",
        "    for time in range(time_params[0],time_params[1] + time_quantum * 2,time_quantum):\n",
        "        vms[time] = [100*[vm_size[0]],100*[vm_size[1]]]\n",
        "    for time in range(time_params[0],time_params[1],time_quantum):\n",
        "        # print(time)\n",
        "        taskQueue_t = taskQueues[time] # get the elements from a certain time\n",
        "        # df_t = df[df['Time'].isin([time])] #get the elements from a certain time\n",
        "        # print(df_t)\n",
        "        # print(\"Length of df for time \" + str(time) + \" is \" + str(len(df_t)))\n",
        "        vm_iter = 0\n",
        "        task_rejected = 0\n",
        "\n",
        "        for task_idx in taskQueue_t:\n",
        "            if(task_rejected == 0):\n",
        "                if(df[\"ExecutionTime\"][task_idx] == 300):\n",
        "                    # print(\"Entered inner for loop, index = \" + str(index) + \" counter = \" + str(ctr) + \" time = \" + str(time))\n",
        "                    if(df['NrmlTaskCores'][task_idx] <= vms[time][0][vm_iter]) and (df['NrmlTaskMem'][task_idx] <= vms[time][1][vm_iter]):\n",
        "                        vms[time][0][vm_iter] -= df['NrmlTaskCores'][task_idx]\n",
        "                        vms[time][1][vm_iter] -= df['NrmlTaskMem'][task_idx]\n",
        "                        finTime = time + 300\n",
        "                        df[\"TurnaroundTime\"][task_idx] = finTime - df[\"Time\"][task_idx]\n",
        "                    else: \n",
        "                        vm_iter += 1\n",
        "                        if(vm_iter < len(vms[time][0])):\n",
        "                            vms[time][0][vm_iter] -= df['NrmlTaskCores'][task_idx]\n",
        "                            vms[time][1][vm_iter] -= df['NrmlTaskMem'][task_idx]\n",
        "                            finTime = time + 300\n",
        "                            df[\"TurnaroundTime\"][task_idx] = finTime - df[\"Time\"][task_idx]\n",
        "                        else:\n",
        "                            task_rejected = 1\n",
        "                            rejectQueue.append(df['TaskID'][task_idx])\n",
        "            elif(df[\"ExecutionTime\"][task_idx] == 300):\n",
        "              rejectQueue.append(df['TaskID'][task_idx])\n",
        "        for task_idx in taskQueue_t:\n",
        "            if(task_rejected == 0):\n",
        "                if(df[\"ExecutionTime\"][task_idx] == 600):\n",
        "                    # print(\"Entered inner for loop, index = \" + str(index) + \" counter = \" + str(ctr) + \" time = \" + str(time))\n",
        "                    if(df['NrmlTaskCores'][task_idx] <= vms[time][0][vm_iter]) and (df['NrmlTaskMem'][task_idx] <= vms[time][1][vm_iter]):\n",
        "                        vms[time][0][vm_iter] -= df['NrmlTaskCores'][task_idx]\n",
        "                        vms[time][1][vm_iter] -= df['NrmlTaskMem'][task_idx]\n",
        "                        vms[time+300][0][vm_iter] -= df['NrmlTaskCores'][task_idx]\n",
        "                        vms[time+300][1][vm_iter] -= df['NrmlTaskMem'][task_idx]\n",
        "                        finTime = time + 600\n",
        "                        df[\"TurnaroundTime\"][task_idx] = finTime - df[\"Time\"][task_idx]\n",
        "                    else: \n",
        "                        vm_iter += 1\n",
        "                        if(vm_iter < len(vms[time][0])):\n",
        "                            vms[time][0][vm_iter] -= df['NrmlTaskCores'][task_idx]\n",
        "                            vms[time][1][vm_iter] -= df['NrmlTaskMem'][task_idx]\n",
        "                            vms[time+300][0][vm_iter] -= df['NrmlTaskCores'][task_idx]\n",
        "                            vms[time+300][1][vm_iter] -= df['NrmlTaskMem'][task_idx]\n",
        "                            finTime = time + 600\n",
        "                            df[\"TurnaroundTime\"][task_idx] = finTime - df[\"Time\"][task_idx]\n",
        "                        else:\n",
        "                            task_rejected = 1\n",
        "                            rejectQueue.append(df['TaskID'][task_idx])\n",
        "            elif(df[\"ExecutionTime\"][task_idx] == 600):\n",
        "              rejectQueue.append(df['TaskID'][task_idx])\n",
        "        print(\"Finished running time {}\".format(time))\n",
        "    return vms,rejectQueue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkz3gfkzr0D_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9d5138-e048-4d8b-dead-54489a28f30c"
      },
      "source": [
        "# Turnaround time optimization\n",
        "totalPwr = 0\n",
        "totalCost = 0\n",
        "rejectQueue = []\n",
        "vms,rejectQueue = sjf([90000,113400],300,[5,10], taskQueues) #90000 - 113100 (113400 not included)\n",
        "for time in range(90000,113400,300): #90000 - 113100 (113400 not included)\n",
        "    vms_t = vms[time]\n",
        "    Pwr_t[time] = powerConsumption(vms_t)\n",
        "    totalPwr = totalPwr + Pwr_t[time]\n",
        "    prcIdx = int((time - 90000)/3600)\n",
        "    Cost_t[time] = Price_t[prcIdx]*Pwr_t[time]\n",
        "    totalCost = totalCost + Cost_t[time]\n",
        "\n",
        "print(\"Turnaround Time optimization:\")\n",
        "print(\"\\tTotal power:\", totalPwr)\n",
        "print(\"\\tTotal cost: \", totalCost)\n",
        "\n",
        "turnaroundtime_sum = 0\n",
        "for index,task in df.iterrows():\n",
        "    turnaroundtime_sum += task.TurnaroundTime\n",
        "avg_turnaroundtime = float(turnaroundtime_sum) / float(len(df)-len(rejectQueue))\n",
        "print(\"\\tAverage turnaround time:\", avg_turnaroundtime)\n",
        "\n",
        "print(\"\\t\" + str(len(rejectQueue)) + \" rejections\")\n",
        "if (len(rejectQueue) > 0):\n",
        "    rejectFileName = \"taskReject_2_turnaround.npy\"\n",
        "    np.save(rejectFileName, rejectQueue)\n",
        "vmFileName = \"VMs_2_turnaround.npy\"\n",
        "np.save(vmFileName, vms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished running time 90000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished running time 90300\n",
            "Finished running time 90600\n",
            "Finished running time 90900\n",
            "Finished running time 91200\n",
            "Finished running time 91500\n",
            "Finished running time 91800\n",
            "Finished running time 92100\n",
            "Finished running time 92400\n",
            "Finished running time 92700\n",
            "Finished running time 93000\n",
            "Finished running time 93300\n",
            "Finished running time 93600\n",
            "Finished running time 93900\n",
            "Finished running time 94200\n",
            "Finished running time 94500\n",
            "Finished running time 94800\n",
            "Finished running time 95100\n",
            "Finished running time 95400\n",
            "Finished running time 95700\n",
            "Finished running time 96000\n",
            "Finished running time 96300\n",
            "Finished running time 96600\n",
            "Finished running time 96900\n",
            "Finished running time 97200\n",
            "Finished running time 97500\n",
            "Finished running time 97800\n",
            "Finished running time 98100\n",
            "Finished running time 98400\n",
            "Finished running time 98700\n",
            "Finished running time 99000\n",
            "Finished running time 99300\n",
            "Finished running time 99600\n",
            "Finished running time 99900\n",
            "Finished running time 100200\n",
            "Finished running time 100500\n",
            "Finished running time 100800\n",
            "Finished running time 101100\n",
            "Finished running time 101400\n",
            "Finished running time 101700\n",
            "Finished running time 102000\n",
            "Finished running time 102300\n",
            "Finished running time 102600\n",
            "Finished running time 102900\n",
            "Finished running time 103200\n",
            "Finished running time 103500\n",
            "Finished running time 103800\n",
            "Finished running time 104100\n",
            "Finished running time 104400\n",
            "Finished running time 104700\n",
            "Finished running time 105000\n",
            "Finished running time 105300\n",
            "Finished running time 105600\n",
            "Finished running time 105900\n",
            "Finished running time 106200\n",
            "Finished running time 106500\n",
            "Finished running time 106800\n",
            "Finished running time 107100\n",
            "Finished running time 107400\n",
            "Finished running time 107700\n",
            "Finished running time 108000\n",
            "Finished running time 108300\n",
            "Finished running time 108600\n",
            "Finished running time 108900\n",
            "Finished running time 109200\n",
            "Finished running time 109500\n",
            "Finished running time 109800\n",
            "Finished running time 110100\n",
            "Finished running time 110400\n",
            "Finished running time 110700\n",
            "Finished running time 111000\n",
            "Finished running time 111300\n",
            "Finished running time 111600\n",
            "Finished running time 111900\n",
            "Finished running time 112200\n",
            "Finished running time 112500\n",
            "Finished running time 112800\n",
            "Finished running time 113100\n",
            "Turnaround Time optimization:\n",
            "\tTotal power: 517877.756953123\n",
            "\tTotal cost:  304931.3287890614\n",
            "\tAverage turnaround time: 433.6180681003259\n",
            "\t340360 rejections\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDyyhCxNoe38"
      },
      "source": [
        "## Phase 2 answers\n",
        "\n",
        "1. Cost is time-dependent, and it's better to optimize for cost if there is not a hard deadline for each task because cost varies by time across the 12-hour timeline, according to the given array, Price_t. If there are hard deadlines for tasks, we are limited in optimizing for cost because cost is time-dependent. In this case, it's better to optimize for power.\n",
        "2. The results of our program show that a preference for greedy or RR depends on what parameters the user wants to optimize. For example, our program showed that while the greedy algorithms optimized either power, cost, or turnaround time, they had a higher rejection rate than the RR algorithm. Therefore, if the user wants to maximize the number of tasks they can allocate to their VMs, then they should use RR. However, if the user wants to minimize cost, power or turnaround time, then they should use one of the greedy algorithms. \n",
        "3. Soft rejection is preferred because itâ€™s less wasteful in the general case. With hard rejection, if a subtask is rejected, we reject all the following subtasks, and all the previously processed subtasks are wasted.\n",
        "4. \n",
        "Round robin scheduling: The round robin scheduling had higher power, cost, and turnaround time than the optimizers for each respective property. However, it resulted in far fewer rejected tasks because the algorithm could focus on ensuring the maximum number of tasks could run rather than optimizing other properties. \n",
        "Power and cost optimization: These methods use the same greedy algorithm and end up with the same results because we assume it would be preferable to allocate the tasks closest to the time quantum when they arrive. In this case, we cannot choose which time to allocate the tasks, they must be allocated for the time they arrive or rejected. Thus, we cannot defer tasks until times where power usage is cheaper. These results show lower power consumption and cost compared to round robin scheduling and turnaround time optimization. \n",
        "Turnaround time: The results for our turnaround time optimization are as follows: we achieved a turnaround time of 433, which is the smallest out of all the algorithms. This optimization was accomplished by using a shortest-job first algorithm, which ultimately rejected tasks that had an execution time of 600. While the optimized turnaround time is not that much lower than the turnaround times produced by the other algorithms, this is because we want to schedule as many tasks as possible, including tasks with an execution time of 600.\n",
        "\n"
      ]
    }
  ]
}